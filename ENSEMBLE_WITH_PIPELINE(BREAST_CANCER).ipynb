{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSEq7WoKJljKRvF65WrQe5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PrateekKumar135/BREAST-CANCER-CLASSIFICATION/blob/main/ENSEMBLE_WITH_PIPELINE(BREAST_CANCER).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AP11eZhg1Ct2"
      },
      "outputs": [],
      "source": [
        "# !pip install dataprep"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install autoviz"
      ],
      "metadata": {
        "id": "sHSAokEnqlJT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from dataprep.eda import create_report\n"
      ],
      "metadata": {
        "id": "aQI5ej1j1hkj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('/content/breast_cancer_WBCD.csv')\n",
        "# create_report(data)"
      ],
      "metadata": {
        "id": "TS-aKXQu1dJg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7qcN86NaDUX",
        "outputId": "0435eba9-d829-496b-8add-ae6c569b4bf6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                           int64\n",
              "diagnosis                   object\n",
              "radius_mean                float64\n",
              "texture_mean               float64\n",
              "perimeter_mean             float64\n",
              "area_mean                  float64\n",
              "smoothness_mean            float64\n",
              "compactness_mean           float64\n",
              "concavity_mean             float64\n",
              "concave points_mean        float64\n",
              "symmetry_mean              float64\n",
              "fractal_dimension_mean     float64\n",
              "radius_se                  float64\n",
              "texture_se                 float64\n",
              "perimeter_se               float64\n",
              "area_se                    float64\n",
              "smoothness_se              float64\n",
              "compactness_se             float64\n",
              "concavity_se               float64\n",
              "concave points_se          float64\n",
              "symmetry_se                float64\n",
              "fractal_dimension_se       float64\n",
              "radius_worst               float64\n",
              "texture_worst              float64\n",
              "perimeter_worst            float64\n",
              "area_worst                 float64\n",
              "smoothness_worst           float64\n",
              "compactness_worst          float64\n",
              "concavity_worst            float64\n",
              "concave points_worst       float64\n",
              "symmetry_worst             float64\n",
              "fractal_dimension_worst    float64\n",
              "Unnamed: 32                float64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from autoviz.AutoViz_Class import AutoViz_Class\n",
        "# AV= AutoViz_Class()\n",
        "# import matplotlib.pyplot as plt\n",
        "# %matplotlib inline\n",
        "\n",
        "# file= pd.DataFrame(data)\n",
        "# # Handle missing values\n",
        "# file.isnull().sum()\n",
        "# file.drop([\"Unnamed: 32\", 'id'], axis=1, inplace=True)\n",
        "# cancer = file.to_csv('cancer.csv')\n",
        "# cancer = '/content/cancer.csv'\n",
        "# AV.AutoViz(filename= cancer)"
      ],
      "metadata": {
        "id": "tWWv4npGqsbE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*This section imports the necessary libraries and modules required for data manipulation, model evaluation, and handling class imbalance.*"
      ],
      "metadata": {
        "id": "vQBZCZbabX-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading some example data\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from imblearn.combine import SMOTETomek\n",
        "from imblearn.under_sampling import TomekLinks"
      ],
      "metadata": {
        "id": "aJ0sEE90bW63"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*In this part, the code reads the breast cancer dataset from a CSV file, checks for missing values, and drops unnecessary columns. It then separates the features (X) and labels (y) from the dataset. Finally, it splits the data into training and testing sets using train_test_split from sklearn.model_selection.*"
      ],
      "metadata": {
        "id": "A42ADODHbnwg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data = pd.read_csv('/content/breast_cancer_WBCD.csv')\n",
        "# Handle missing values\n",
        "data.isnull().sum()\n",
        "data.drop([\"Unnamed: 32\", 'id'], axis=1, inplace=True)\n",
        "# Split data into features (X) and labels (y)\n",
        "X = data.drop(\"diagnosis\", axis=1)\n",
        "y = data.diagnosis\n",
        "# Split test and train data\n",
        "X_train,X_test,y_train,y_test= train_test_split(X,y,test_size=0.2)"
      ],
      "metadata": {
        "id": "lGgczpsl1dQE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "outputId": "2a492d50-5512-4dbb-85b3-a325c642a915"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method _RepeatedSplits.split of RepeatedStratifiedKFold(n_repeats=3, n_splits=10, random_state=None)>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>sklearn.model_selection._split._RepeatedSplits.split</b><br/>def split(X, y=None, groups=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py</a>Generates indices to split data into training and test set.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "X : array-like of shape (n_samples, n_features)\n",
              "    Training data, where `n_samples` is the number of samples\n",
              "    and `n_features` is the number of features.\n",
              "\n",
              "y : array-like of shape (n_samples,)\n",
              "    The target variable for supervised learning problems.\n",
              "\n",
              "groups : array-like of shape (n_samples,), default=None\n",
              "    Group labels for the samples used while splitting the dataset into\n",
              "    train/test set.\n",
              "\n",
              "Yields\n",
              "------\n",
              "train : ndarray\n",
              "    The training set indices for that split.\n",
              "\n",
              "test : ndarray\n",
              "    The testing set indices for that split.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 1447);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*This code creates an instance of RepeatedStratifiedKFold for cross-validation. It will split the data into 10 folds and repeat the process 3 times, ensuring that the class distribution is preserved in each fold.*"
      ],
      "metadata": {
        "id": "Cua5V6tkblsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv_ori=RepeatedStratifiedKFold(n_splits=10, n_repeats=3)\n",
        "cv_ori.split"
      ],
      "metadata": {
        "id": "MpIOxgzzbg3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score,recall_score,precision_score\n",
        "lr=LogisticRegression().fit(X_train,y_train)\n",
        "y_pred = lr.predict(X_test)\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "recall =recall_score(y_test,y_pred,average='macro')\n",
        "precision = precision_score(y_test,y_pred,average='macro')\n",
        "print(print(f'Accuracy : {accuracy}'))\n",
        "print(print(f'precision : {precision}'))\n",
        "print(print(f'Recall : {recall}'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWA84L3DtMNO",
        "outputId": "6c1189ea-7374-4394-fb91-300734bdc511"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 0.956140350877193\n",
            "None\n",
            "precision : 0.9683544303797469\n",
            "None\n",
            "Recall : 0.9375\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*This section trains a Logistic Regression model on the training data, makes predictions on the test data, and calculates the accuracy, precision, and recall scores for the model.\n",
        "\n",
        "The rest of the code follows a similar pattern, where it trains and evaluates several other models, such as K-Nearest Neighbors (KNN), Support Vector Machines (SVM), Voting Ensemble, Gradient Boosting, AdaBoost, and Perceptron Neural Network.*"
      ],
      "metadata": {
        "id": "acj0bmUKbzJ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LOGISTIC REGRESSION**"
      ],
      "metadata": {
        "id": "3JhwDzJKqb4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from itertools import product\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import KFold,cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "##feature Scaling\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "YlPXvJlzb8v2"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*This part imports additional libraries and modules required for feature scaling, dimensionality reduction (PCA), and ensemble methods.*"
      ],
      "metadata": {
        "id": "n9LIHcpucFiE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "steps=[ ('scaler',StandardScaler()),\n",
        "        (\"PCA\",PCA(n_components=20)),\n",
        "        (\"clf1\", LogisticRegression())\n",
        "      ]\n",
        "\n",
        "# print(steps)\n",
        "pipe=Pipeline(steps)\n",
        "pipe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "LCoouy11cCSb",
        "outputId": "48bd74ab-8b09-4d93-fe33-8226ca1391c2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('scaler', StandardScaler()), ('PCA', PCA(n_components=20)),\n",
              "                ('clf1', LogisticRegression())])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;PCA&#x27;, PCA(n_components=20)),\n",
              "                (&#x27;clf1&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;PCA&#x27;, PCA(n_components=20)),\n",
              "                (&#x27;clf1&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=20)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*This code creates a Pipeline object that chains together the steps of feature scaling (using StandardScaler), dimensionality reduction (using PCA with 20 principal components), and the Logistic Regression model.*"
      ],
      "metadata": {
        "id": "RYgzthZicPXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model\n",
        "scoring=['accuracy','precision_macro','recall_macro']\n",
        "scores_ori = cross_validate(pipe, X, y, scoring=scoring, cv=cv_ori, n_jobs=-1)\n",
        "# summarize performance\n",
        "print('Mean Accuracy: %.4f' % np.mean(scores_ori['test_accuracy']))\n",
        "print('Mean Precision: %.4f' % np.mean(scores_ori['test_precision_macro']))\n",
        "print('Mean Recall: %.4f' % np.mean(scores_ori['test_recall_macro']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fFHXzIh1dK-",
        "outputId": "216fd64e-c71d-4655-b61e-2a63ee1d6bee"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Accuracy: 0.9777\n",
            "Mean Precision: 0.9782\n",
            "Mean Recall: 0.9748\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*This section evaluates the performance of the Pipeline object using cross_validate from sklearn.model_selection. It prints the mean accuracy, precision, and recall scores obtained from the repeated stratified cross-validation.\n",
        "\n",
        "The code continues to create and evaluate similar Pipeline objects for other models, such as KNN, SVM, Voting Ensemble, Gradient Boosting, AdaBoost, and Perceptron Neural Network.*"
      ],
      "metadata": {
        "id": "tWSTtCnucYbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=4).fit(X_train,y_train)\n",
        "y_pred = knn.predict(X_test)\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "recall =recall_score(y_test,y_pred,average='macro')\n",
        "precision = precision_score(y_test,y_pred,average='macro')\n",
        "print(print(f'Accuracy : {accuracy}'))\n",
        "print(print(f'precision : {precision}'))\n",
        "print(print(f'Recall : {recall}'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyMmHcrsuubC",
        "outputId": "49c6e437-a493-49fc-ac85-866385e258c4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 0.9298245614035088\n",
            "None\n",
            "precision : 0.9415441176470588\n",
            "None\n",
            "Recall : 0.9057432432432433\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**KNN**"
      ],
      "metadata": {
        "id": "jXPRN70AqYsu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "steps_1=[ ('scaler',StandardScaler()),\n",
        "        (\"PCA\",PCA(n_components=20)),\n",
        "       (\"clf2\", KNeighborsClassifier(n_neighbors=4))\n",
        "        ]\n",
        "pipe_1 = Pipeline(steps_1)\n",
        "# Evaluate model\n",
        "scoring=['accuracy','precision_macro','recall_macro']\n",
        "scores_ori = cross_validate(pipe_1, X, y, scoring=scoring, cv=cv_ori, n_jobs=-1)\n",
        "# summarize performance\n",
        "print('Mean Accuracy: %.4f' % np.mean(scores_ori['test_accuracy']))\n",
        "print('Mean Precision: %.4f' % np.mean(scores_ori['test_precision_macro']))\n",
        "print('Mean Recall: %.4f' % np.mean(scores_ori['test_recall_macro']))\n",
        "# pipe_1.fit(X_train_smote,y_train_smote)\n",
        "# print(pipe_1)\n",
        "# kfold=KFold(10)\n",
        "# results=cross_val_score(pipe_1,X,y,cv=kfold)\n",
        "# print(results)\n",
        "# print(f'Max :{np.max(results)}')\n",
        "# print(f'Min :{np.min(results)}')\n",
        "# print(np.mean(results))"
      ],
      "metadata": {
        "id": "fJedcdc8zEag",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "699a7f37-355f-4ec9-8d75-b46bb3a81066"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Accuracy: 0.9648\n",
            "Mean Precision: 0.9720\n",
            "Mean Recall: 0.9545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "svc = SVC(kernel='rbf',probability=True).fit(X_train,y_train)\n",
        "y_pred = svc.predict(X_test)\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "recall =recall_score(y_test,y_pred,average='macro')\n",
        "precision = precision_score(y_test,y_pred,average='macro')\n",
        "print(print(f'Accuracy : {accuracy}'))\n",
        "print(print(f'precision : {precision}'))\n",
        "print(print(f'Recall : {recall}'))\n",
        "# print(print(f'Accuracy : {accuracy}'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xy8ciJH_vekO",
        "outputId": "08c51c68-6fdc-491c-c40c-a52d51994d25"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 0.9210526315789473\n",
            "None\n",
            "precision : 0.927124773960217\n",
            "None\n",
            "Recall : 0.8989864864864865\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SVC**"
      ],
      "metadata": {
        "id": "xw4S-cX7qVEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "\n",
        "steps_2=[ ('scaler',StandardScaler()),\n",
        "          (\"PCA\",PCA(n_components=20)),\n",
        "         (\"clf3 \",SVC(kernel='rbf', probability=True)),\n",
        "         ]\n",
        "print(steps_2)\n",
        "pipe_2 = Pipeline(steps_2)\n",
        "# Evaluate model\n",
        "scoring=['accuracy','precision_macro','recall_macro']\n",
        "scores_ori = cross_validate(pipe_2, X, y, scoring=scoring, cv=cv_ori, n_jobs=-1)\n",
        "# summarize performance\n",
        "print('Mean Accuracy: %.4f' % np.mean(scores_ori['test_accuracy']))\n",
        "print('Mean Precision: %.4f' % np.mean(scores_ori['test_precision_macro']))\n",
        "print('Mean Recall: %.4f' % np.mean(scores_ori['test_recall_macro']))\n",
        "# print(pipe_2.fit(cv_ori))\n",
        "# print(pipe_2)\n",
        "# print(pipe_2.fit(X_train_smote,y_train_smote))\n",
        "# kfold=KFold(10)\n",
        "# # scoring=['accuracy','precision_macro','recall_macro']\n",
        "# results=cross_val_score(pipe_2,X,y,cv=kfold)\n",
        "# print(results)\n",
        "# print(f'Max :{np.max(results)}')\n",
        "# print(f'Min :{np.min(results)}')\n",
        "# print(np.mean(results))"
      ],
      "metadata": {
        "id": "4khYTcVI1M_v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "932962fe-9ff8-4939-fd19-67d5c36d647e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('scaler', StandardScaler()), ('PCA', PCA(n_components=20)), ('clf3 ', SVC(probability=True))]\n",
            "Mean Accuracy: 0.9713\n",
            "Mean Precision: 0.9722\n",
            "Mean Recall: 0.9672\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VOTING ENSEMBLE**"
      ],
      "metadata": {
        "id": "xN_GZ5f6qPMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "steps_3=[ ('scaler',StandardScaler()),\n",
        "          (\"PCA\",PCA(n_components=20)),\n",
        "      (\"eclf\", VotingClassifier(estimators=[('lg',LogisticRegression()), ('knn',KNeighborsClassifier(n_neighbors=4)), ('svc',SVC(kernel='rbf', probability=True))],voting='hard'))]\n",
        "print(steps_3)\n",
        "pipe_3 = Pipeline(steps_3)\n",
        "# Evaluate model\n",
        "scoring=['accuracy','precision_macro','recall_macro']\n",
        "scores_ori = cross_validate(pipe_3, X, y, scoring=scoring, cv=cv_ori, n_jobs=-1)\n",
        "# summarize performance\n",
        "print('Mean Accuracy: %.4f' % np.mean(scores_ori['test_accuracy']))\n",
        "print('Mean Precision: %.4f' % np.mean(scores_ori['test_precision_macro']))\n",
        "print('Mean Recall: %.4f' % np.mean(scores_ori['test_recall_macro']))\n",
        "# print(pipe_3.fit(X_train_smote,y_train_smote))\n",
        "# kfold=KFold(10)\n",
        "# results=cross_val_score(pipe_3,X,y,cv=kfold)\n",
        "# print(results)\n",
        "# print(f'Max :{np.max(results)}')\n",
        "# print(f'Min :{np.min(results)}')\n",
        "# print(np.mean(results))"
      ],
      "metadata": {
        "id": "Z_snBYp04207",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d422b9eb-914a-4638-dcfe-fe0cd82967eb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('scaler', StandardScaler()), ('PCA', PCA(n_components=20)), ('eclf', VotingClassifier(estimators=[('lg', LogisticRegression()),\n",
            "                             ('knn', KNeighborsClassifier(n_neighbors=4)),\n",
            "                             ('svc', SVC(probability=True))]))]\n",
            "Mean Accuracy: 0.9783\n",
            "Mean Precision: 0.9808\n",
            "Mean Recall: 0.9735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "gb = GradientBoostingClassifier(n_estimators=1000,learning_rate=0.01).fit(X_train,y_train)\n",
        "y_pred = gb.predict(X_test)\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "recall =recall_score(y_test,y_pred,average='macro')\n",
        "precision = precision_score(y_test,y_pred,average='macro')\n",
        "print(print(f'Accuracy : {accuracy}'))\n",
        "print(print(f'precision : {precision}'))\n",
        "print(print(f'Recall : {recall}'))\n",
        "# print(print(f'Accuracy : {accuracy}'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pG2kaiBYyWia",
        "outputId": "1a618e5b-2c75-406b-bf3e-1518ab4d9d14"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 0.9649122807017544\n",
            "None\n",
            "precision : 0.9671052631578947\n",
            "None\n",
            "Recall : 0.9557432432432433\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GRADIENT-BOOSTING**"
      ],
      "metadata": {
        "id": "KvM-trSFkFyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Gradient Boosting Classifier for ensemble learning\n",
        "# gb_classifier = GradientBoostingClassifier(n_estimators=2050, learning_rate=0.01, random_state=42)\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "steps_4=[ ('scaler',StandardScaler()),\n",
        "          (\"PCA\",PCA(n_components=20)),\n",
        "      (\"gb_classifier\", GradientBoostingClassifier(n_estimators=1000, learning_rate=0.01))]\n",
        "print(steps_4)\n",
        "pipe_4 = Pipeline(steps_4)\n",
        "# Evaluate model\n",
        "# scoring=['accuracy','precision_macro','recall_macro']\n",
        "# scores_ori = cross_validate(pipe_4, X, y, scoring=scoring, cv=cv_ori, n_jobs=-1)\n",
        "# # summarize performance\n",
        "# print('Mean Accuracy: %.4f' % np.mean(scores_ori['test_accuracy']))\n",
        "# print('Mean Precision: %.4f' % np.mean(scores_ori['test_precision_macro']))\n",
        "# print('Mean Recall: %.4f' % np.mean(scores_ori['test_recall_macro']))\n",
        "# print(pipe_4.fit(X_train_smote,y_train_smote))\n",
        "# kfold=KFold(10)\n",
        "# results=cross_val_score(pipe_4,X,y,cv=kfold)\n",
        "# print(results)\n",
        "# print(f'Max :{np.max(results)}')\n",
        "# print(f'Min :{np.min(results)}')\n",
        "# print(np.mean(results))"
      ],
      "metadata": {
        "id": "kF96f12nfCEw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14c3ef3a-08e5-4388-847e-6756fc09aa65"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('scaler', StandardScaler()), ('PCA', PCA(n_components=20)), ('gb_classifier', GradientBoostingClassifier(learning_rate=0.01, n_estimators=1000))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "ada = AdaBoostClassifier(n_estimators=1000).fit(X_train,y_train)\n",
        "y_pred = ada.predict(X_test)\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "recall =recall_score(y_test,y_pred,average='macro')\n",
        "precision = precision_score(y_test,y_pred,average='macro')\n",
        "print(print(f'Accuracy : {accuracy}'))\n",
        "print(print(f'precision : {precision}'))\n",
        "print(print(f'Recall : {recall}'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfwqvaPy0DM3",
        "outputId": "65aa7ad4-84e6-4e0e-c3fe-2a1d0f713e70"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 0.9649122807017544\n",
            "None\n",
            "precision : 0.9671052631578947\n",
            "None\n",
            "Recall : 0.9557432432432433\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ADA BOOST**"
      ],
      "metadata": {
        "id": "NAsomcY8ot8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "steps_5=[ ('scaler',StandardScaler()),(\"PCA\",PCA(n_components=20)),\n",
        "      (\"ada_classifier\", AdaBoostClassifier(n_estimators=1000))]\n",
        "print(steps_5)\n",
        "pipe_5 = Pipeline(steps_5)\n",
        "# Evaluate model\n",
        "# scoring=['accuracy','precision_macro','recall_macro']\n",
        "# scores_ori = cross_validate(pipe_5, X, y, scoring=scoring, cv=cv_ori, n_jobs=-1)\n",
        "# # summarize performance\n",
        "# print('Mean Accuracy: %.4f' % np.mean(scores_ori['test_accuracy']))\n",
        "# print('Mean Precision: %.4f' % np.mean(scores_ori['test_precision_macro']))\n",
        "# print('Mean Recall: %.4f' % np.mean(scores_ori['test_recall_macro']))\n",
        "# print(pipe_5.fit(X_train_smote,y_train_smote))\n",
        "# kfold=KFold(10)\n",
        "# results=cross_val_score(pipe_5,X,y,cv=kfold)\n",
        "# print(results)\n",
        "# print(f'Max :{np.max(results)}')\n",
        "# print(f'Min :{np.min(results)}')\n",
        "# print(np.mean(results))"
      ],
      "metadata": {
        "id": "r7ya2aGSkEoc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9123659-ed3d-4b94-f83b-06f635d131a6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('scaler', StandardScaler()), ('PCA', PCA(n_components=20)), ('ada_classifier', AdaBoostClassifier(n_estimators=1000))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "pnn = MLPClassifier(hidden_layer_sizes=500).fit(X_train,y_train)\n",
        "y_pred = pnn.predict(X_test)\n",
        "# y_pred = gb.predict(X_test)\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "recall =recall_score(y_test,y_pred,average='macro')\n",
        "precision = precision_score(y_test,y_pred,average='macro')\n",
        "print(print(f'Accuracy : {accuracy}'))\n",
        "print(print(f'precision : {precision}'))\n",
        "print(print(f'Recall : {recall}'))\n",
        "# accuracy = accuracy_score(y_test,y_pred)\n",
        "# print(print(f'Accuracy : {accuracy}'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JuYJY-FzoGS",
        "outputId": "4a952623-a378-49f8-e353-6fb962198273"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 0.8596491228070176\n",
            "None\n",
            "precision : 0.8571428571428572\n",
            "None\n",
            "Recall : 0.8918918918918919\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PERCEPTRON NEURAL NETWORK**"
      ],
      "metadata": {
        "id": "M466sZneoyAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "steps_6=[ ('scaler',StandardScaler()),(\"PCA\",PCA(n_components=20)),\n",
        "      (\"mlp_classifier\", MLPClassifier(hidden_layer_sizes=500))]\n",
        "print(steps_6)\n",
        "pipe_6 = Pipeline(steps_6)\n",
        "# Evaluate model\n",
        "# scoring=['accuracy','precision_macro','recall_macro']\n",
        "# scores_ori = cross_validate(pipe_6, X, y, scoring=scoring, cv=cv_ori, n_jobs=-1)\n",
        "# # summarize performance\n",
        "# print('Mean Accuracy: %.4f' % np.mean(scores_ori['test_accuracy']))\n",
        "# print('Mean Precision: %.4f' % np.mean(scores_ori['test_precision_macro']))\n",
        "# print('Mean Recall: %.4f' % np.mean(scores_ori['test_recall_macro']))\n",
        "# print(pipe_6.fit(X_train_smote,y_train_smote))\n",
        "\n",
        "# kfold=KFold(10)\n",
        "# results=cross_val_score(pipe_6,X,y,cv=kfold)\n",
        "# print(results)\n",
        "# print(f'Max :{np.max(results)}')\n",
        "# print(f'Min :{np.min(results)}')\n",
        "# print(np.mean(results))"
      ],
      "metadata": {
        "id": "QgaDbH-rkEwT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de8809d2-1268-4e0f-86c9-1d81bd676169"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('scaler', StandardScaler()), ('PCA', PCA(n_components=20)), ('mlp_classifier', MLPClassifier(hidden_layer_sizes=500))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mypipes =[pipe, pipe_1,pipe_2,pipe_3,pipe_4,pipe_5,pipe_6]\n",
        "accuracy = 0\n",
        "precision_macro=0\n",
        "recall_macro = 0\n",
        "pipelines = ''\n",
        "pipeline_dict={0:'LogisticRegresion', 1:'KNN', 2:'SVC', 3:'Voting Ensemble', 4:'Gradient boost',5:'Ada boost',6:'Perceptron Neural Network'}\n",
        "scoring=['accuracy','precision_macro','recall_macro']\n",
        "for i,model in enumerate(mypipes):\n",
        "  scores_ori = cross_validate(model, X, y, scoring=scoring, cv=cv_ori, n_jobs=-1)\n",
        "  print(pipeline_dict[i])\n",
        "  print('Mean Accuracy: %.4f' % np.mean(scores_ori['test_accuracy']))\n",
        "  print('Mean Precision: %.4f' % np.mean(scores_ori['test_precision_macro']))\n",
        "  print('Mean Recall: %.4f' % np.mean(scores_ori['test_recall_macro']))"
      ],
      "metadata": {
        "id": "SOU2MrlskEys",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "124ff12e-f2c8-4e74-c89f-133395196044"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegresion\n",
            "Mean Accuracy: 0.9777\n",
            "Mean Precision: 0.9791\n",
            "Mean Recall: 0.9742\n",
            "KNN\n",
            "Mean Accuracy: 0.9648\n",
            "Mean Precision: 0.9715\n",
            "Mean Recall: 0.9548\n",
            "SVC\n",
            "Mean Accuracy: 0.9754\n",
            "Mean Precision: 0.9762\n",
            "Mean Recall: 0.9724\n",
            "Voting Ensemble\n",
            "Mean Accuracy: 0.9754\n",
            "Mean Precision: 0.9786\n",
            "Mean Recall: 0.9698\n",
            "Gradient boost\n",
            "Mean Accuracy: 0.9561\n",
            "Mean Precision: 0.9578\n",
            "Mean Recall: 0.9504\n",
            "Ada boost\n",
            "Mean Accuracy: 0.9601\n",
            "Mean Precision: 0.9618\n",
            "Mean Recall: 0.9543\n",
            "Perceptron Neural Network\n",
            "Mean Accuracy: 0.9789\n",
            "Mean Precision: 0.9807\n",
            "Mean Recall: 0.9746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*In this final section, the code creates a list mypipes containing all the Pipeline objects for the different models. It then iterates over this list and performs repeated stratified cross-validation on each model using cross_validate. It prints the name of the model and the mean accuracy, precision, and recall scores for each model.*\n",
        "**Overall, this code explores several machine learning models for the breast cancer classification problem. It uses techniques like feature scaling, dimensionality reduction (PCA), and ensemble methods (Voting Ensemble, Gradient Boosting, AdaBoost) to improve the performance of the models. The code evaluates the models using repeated stratified cross-validation, which provides a more robust estimate of the model's performance by considering multiple splits of the data and preserving the class distribution in each fold.**"
      ],
      "metadata": {
        "id": "UpJHZXWEcjIM"
      }
    }
  ]
}